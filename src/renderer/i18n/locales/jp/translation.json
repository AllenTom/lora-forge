{
  "args": {
    "no_metadata": "メタデータを出力先モデルに保存しない",
    "save_model_as": "モデル保存時の形式（デフォルトはsafetensors）",
    "unet_lr": "U-Netの学習率",
    "text_encoder_lr": "Text Encoderの学習率",
    "network_weights": "学習するネットワークの初期重み",
    "network_dim": "モジュールの次元数（ネットワークにより定義は異なります）",
    "network_alpha": "LoRaの重み調整のalpha値、デフォルト1（旧バージョンと同じ動作をするにはnetwork_dimと同じ値を指定）",
    "network_dropout": "訓練時に毎ステップでニューロンをdropする（0またはNoneはdropoutなし、1は全ニューロンをdropout）",
    "base_weights": "学習前にあらかじめモデルにマージするnetworkの重みファイル",
    "no_half_vae": "mixed precisionでも fp16/bf16 VAEを使わずfloat VAEを使う",
    "v2": "Stable Diffusion 2.0のモデルを読み込む",
    "v_parameterization": "v-parameterization学習を有効にする",
    "pretrained_model_name_or_path": "学習元モデル、Diffusers形式モデルのディレクトリまたはStableDiffusionのckptファイル",
    "tokenizer_cache_dir": "Tokenizerをキャッシュするディレクトリ（ネット接続なしでの学習のため）",
    "optimizer_type": "使用するオプティマイザ",
    "use_8bit_adam": "8bit AdamWオプティマイザを使用する（bitsandbytesが必要）",
    "use_lion_optimizer": "Lionオプティマイザを使用する（lion-pytorchが必要）",
    "learning_rate": "学習率",
    "max_grad_norm": "最大勾配ノルム、クリッピングしない場合は0",
    "optimizer_args": "オプティマイザの追加引数",
    "lr_scheduler_type": "カスタムスケジューラモジュール",
    "lr_scheduler_args": "スケジューラの追加引数",
    "lr_scheduler": "学習率のスケジューラ",
    "lr_warmup_steps": "学習率スケジューラのウォームアップステップ数（デフォルトは0）",
    "lr_scheduler_num_cycles": "コサインスケジューラのリスタート回数",
    "lr_scheduler_power": "ポリノミアルスケジューラのポリノミアルパワー",
    "output_dir": "学習後のモデル出力先ディレクトリ",
    "output_name": "学習後のモデルの拡張子を除くファイル名",
    "huggingface_repo_id": "huggingfaceにアップロードするリポジトリ名",
    "huggingface_repo_type": "huggingfaceにアップロードするリポジトリの種類",
    "huggingface_path_in_repo": "huggingfaceにアップロードするファイルのパス",
    "huggingface_token": "huggingfaceのトークン",
    "huggingface_repo_visibility": "huggingfaceにアップロードするリポジトリの公開設定（'public'で公開、'private'またはNoneで非公開）",
    "save_state_to_huggingface": "huggingfaceにstateを保存する",
    "resume_from_huggingface": "huggingfaceから学習を再開する(例: --resume {repo_id}/{path_in_repo}:{revision}:{repo_type})",
    "async_upload": "huggingfaceに非同期でアップロードする",
    "save_precision": "保存時に精度を変更して保存する",
    "save_every_n_epochs": "学習中のモデルを指定エポックごとに保存する",
    "save_every_n_steps": "学習中のモデルを指定ステップごとに保存する",
    "save_n_epoch_ratio": "学習中のモデルを指定のエポック割合で保存する（たとえば5を指定すると最低5個のファイルが保存される）",
    "save_last_n_epochs": "指定エポックごとにモデルを保存するとき最大Nエポック保存する（古いチェックポイントは削除する）",
    "save_last_n_epochs_state": "最大Nエポックstateを保存する（--save_last_n_epochsの指定を上書きする）",
    "save_last_n_steps": "指定ステップごとにモデルを保存するとき、このステップ数経過するまで保存する（このステップ数経過したら削除する）",
    "save_last_n_steps_state": "指定ステップごとにstateを保存するとき、このステップ数経過するまで保存する（このステップ数経過したら削除する。--save_last_n_stepsを上書きする）",
    "save_state": "optimizerなど学習状態も含めたstateを追加で保存する",
    "resume": "学習再開するモデルのstate",
    "train_batch_size": "学習時のバッチサイズ",
    "max_token_length": "text encoderのトークンの最大長（未指定で75、150または225が指定可）",
    "mem_eff_attn": "CrossAttentionに省メモリ版attentionを使う",
    "logging_dir":"ログ出力のためのディレクトリのパス",
    "log_with":"使用するログツール（選択肢: tensorboard, wandb, all）",
    "log_prefix":"各ログディレクトリに接頭辞を追加",
    "log_tracker_name":"ログ出力に使用するトラッカーの名前",
    "log_tracker_config":"ログ出力に使用するトラッカーの設定ファイルのパス",
    "wandb_api_key":"トレーニングを開始する前にログインするためのWandB APIキーを指定（オプション）",
    "noise_offset":"この値でノイズオフセットを有効にする（推奨: 約0.1）",
    "multires_noise_iterations":"このイテレーション数でマルチレベルノイズを有効にする（推奨: 約6-10）",
    "multires_noise_discount": "Multires ... noiseのdiscount値を設定する（--multires_noise_iterations指定時のみ有効）",
    "adaptive_noise_scale": "latentの平均値の絶対値 * ... この値をnoise_offsetに加算する（Noneの場合は無効、デフォルト）",
    "zero_terminal_snr": "noise schedulerのbetasを修正して、zero terminal SNRを強制する",
    "min_timestep": "U-Net学習時のtime stepの最小値を設定する（0999で指定、省略時はデフォルト値(0)）",
    "max_timestep": "U-Net学習時のtime stepの最大値を設定する（11000で指定、省略時はデフォルト値(1000)）",
    "lowram": "メインメモリが少ない環境向け最適化を有効にする。たとえばVRAMにモデルを読み込むなど（ColabやKaggleなどRAMに比べてVRAMが多い環境向け）",
    "sample_every_n_steps": "学習中のモデルで指定ステップごとにサンプル出力する",
    "sample_every_n_epochs": "学習中のモデルで指定エポックごとにサンプル出力する（ステップ数指定を上書きします）",
    "sample_prompts": "学習中モデルのサンプル出力用プロンプトのファイル",
    "sample_sampler": "サンプル画像のためのサンプラー（スケジューラ）の種類",
    "config_file": ".tomlファイルを使用してハイパーパラメータを引数ではなく渡す",
    "output_config": "指定された.tomlファイルにコマンドライン引数を出力する",
    "metadata_title": "モデルメタデータのタイトル（デフォルトはoutput_name）",
    "metadata_author": "モデルメタデータの著者名",
    "metadata_description": "モデルメタデータの説明",
    "metadata_license": "モデルメタデータのライセンス",
    "metadata_tags": "モデルメタデータのタグ（カンマ区切り）",
    "prior_loss_weight": "正則化画像のlossの重み",
    "train_data_dir": "学習画像データのディレクトリ",
    "shuffle_caption": "コンマで区切られたcaptionの各要素をshuffleする",
    "caption_extension": "読み込むcaptionファイルの拡張子",
    "caption_extention": "読み込むcaptionファイルの拡張子（スペルミスを残してあります）",
    "keep_tokens": "captionのシャッフル時に、先頭からこの個数のトークンをシャッフルしないで残す（トークンはカンマ区切りの各部分を意味する）",
    "color_aug": "学習時に色合いのaugmentationを有効にする",
    "flip_aug": "学習時に左右反転のaugmentationを有効にする",
    "face_crop_aug_range": "学習時に顔を中心とした切り出しaugmentationを有効にするときは倍率を指定する（例：2.0,4.0）",
    "random_crop": "ランダムクロップを有効にする（スタイルトレーニングのための顔中心のクロップ拡張）",
    "debug_dataset": "デバッグ用の画像を表示する（トレーニングは行わない）",
    "resolution": "トレーニング中の解像度（'size'または'width,height'）",
    "cache_latents": "VRAM使用量を減らすために潜在変数をメインメモリにキャッシュする（拡張は無効にする必要があります）",
    "vae_batch_size": "潜在変数のキャッシュのバッチサイズ",
    "cache_latents_to_disk": "VRAM使用量を減らすために潜在変数をディスクにキャッシュする（拡張は無効にする必要があります）",
    "enable_bucket": "マルチアスペクト比トレーニング用のバケットを有効にする",
    "min_bucket_reso": "バケットの最小解像度",
    "max_bucket_reso": "バケットの最大解像度",
    "bucket_reso_steps": "バケットの解像度のステップ数、8で割り切れることが推奨されます",
    "bucket_no_upscale": "画像を拡大せずbucketを作成します",
    "token_warmup_min": "タグ数をN個から増やしながら学習する",
    "token_warmup_step": "N（N<1ならNmax_train_steps）ステップでタグ長が最大になる。デフォルトは0（最初から最大）",
    "dataset_class": "任意のデータセットを用いるときのクラス名 (package.module.Class)",
    "use_safetensors": "checkpoint、モデルをsafetensors形式で保存する（save_model_as未指定時）",
    "clip_skip": "text encoderの後ろからn番目の層の出力を用いる（nは1以上）",
    "full_fp16":"勾配も含めてfp16で学習する",
    "max_train_epochs":"学習エポック数（max_train_stepsを上書きします）",
    "max_data_loader_n_workers":"DataLoaderの最大プロセス数（小さい値ではメインメモリの使用量が減りエポック間の待ち時間が減りますが、データ読み込みは遅くなります）",
    "persistent_data_loader_workers":"DataLoader のワーカーを持続させる (エポック間の時間差を少なくするのに有効だが、より多くのメモリを消費する可能性がある)",
    "seed":"学習時の乱数のseed",
    "gradient_checkpointing":"grandient checkpointingを有効にする",
    "gradient_accumulation_steps":"学習時に逆伝播をする前に勾配を合計するステップ数",
    "mixed_precision":"混合精度を使う場合、その精度",
    "xformers":"CrossAttentionにxformersを使う",
    "vae":"VAEを入れ替える場合、VAEのcheckpointファイルまたはディレクトリ",
    "max_train_steps":"学習ステップ数",
    "reg_data_dir":"正則化画像データのディレクトリ"
  }
}
