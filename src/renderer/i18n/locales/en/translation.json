{
  "menu": {
    "openLog": "Open Log",
    "exportLog": "Export Log",
    "settings": "Settings",
    "scriptManager": "Script Manager",
    "openOutputModelFolder": "Open Output Model Folder",
    "startPreviewService": "Start Preview Service",
    "generationPreviewImageProps": "Generation Preview Image Props",
    "loraPresetManager": "LoRa Preset Manager",
    "addTag": "Add Tag",
    "tag": "Tag",
    "importFromFolder": "Import From Folder",
    "openImportFolder": "Open Import Folder",
    "source": "Source",
    "openDatasetFolder": "Open Dataset Folder",
    "generateDataset": "Generate Dataset",
    "newDataset": "New Dataset",
    "dataset": "Dataset",
    "openProjectFolder": "Open Project Folder",
    "saveProject": "Save",
    "openProject": "Open",
    "file": "File",
    "previewManager": "Preview Manager",
    "newProject": "New Project",
    "importOriginalImages": "Import Original Images"
  },
  "dialogs": {
    "exportLog": {
      "success": "Log exported successfully"
    },
    "openProject": {
      "title": "Select Project Folder"
    },
    "newDataset": {
      "title": "New Dataset",
      "name": "Name",
      "step": "Step",
      "create": "Create"
    },
    "importFromFolder": {
      "title": "Import From Folder",
      "imageSourceFolder": "Image source folder",
      "import": "Import",
      "selectFolderTitle": "Select Folder",
      "select": "Select",
      "width": "Width",
      "height": "Height",
      "useDeepdanbooruToTagImage": "Use DeepDanbooru to tag image",
      "autoCreateWithImport": "Auto create dataset with import",
      "folderName": "Folder Name",
      "step": "Step",
      "outputMessage": "Output Message",
      "importBtn": "Import",
      "interrupt": "Interrupt",
      "close": "Close",
      "startPreprocess": "Start Preprocess",
      "preprocessDone": "Preprocess Done",
      "preprocessProgress": "Processing {{index}}/{{total}}",
      "downloadModelProgress": "Downloading Model {{progress}}%",
      "menu": "menu",
      "fromFolder": "From Folder",
      "fromImage": "From Images",
      "clearAll": "Clear all"
    },
    "addTagDialog": {
      "title": "Batch add tag",
      "tagsLabel": "Add tags to item,use , to split",
      "add": "Add",
      "cancel": "Cancel"
    },
    "loraPresetManager": {
      "title": "LoRa Preset Manager",
      "name": "Name",
      "actions": "Actions",
      "new": "New",
      "builtIn": "Built-in",
      "delete": "Delete"
    },
    "newLoraPreset": {
      "title": "New LoRa Preset",
      "name": "Name",
      "create": "Create",
      "cancel": "Cancel"
    },
    "configGeneratePreviewProps": {
      "title": "Generation Preview Image Props",
      "apply": "Apply",
      "sdModel": "Stable diffusion model",
      "prompt": "Prompt",
      "negativePrompt": "Negative Prompt",
      "width": "Width",
      "height": "Height",
      "steps": "Steps",
      "samplerName": "Sampler Name",
      "cfgScale": "cfg_scale",
      "seed": "Seed"
    },
    "scriptManager": {
      "downloadScript": "Download script",
      "downloadScriptSuccess": "Download script success",
      "downloadScriptFailed": "Download script failed,{{e}}",
      "updateScript": "Update script",
      "updatingScript": "Updating script",
      "updateScriptSuccess": "Update script success",
      "updateScriptFailed": "Update script failed,{{e}}",
      "title": "Script Manager",
      "scriptPath": "Script path",
      "selectPath": "Select path",
      "downloadScriptTitle": "Download script",
      "downloadScriptMessage": "Download script",
      "installScript": "Install script",
      "openFolder": "Open folder",
      "saveAndClose": "Save and close",
      "close": "Close",
      "useCnSourceToInstall": "Use CN source to install",
      "useCnRepo": "Use CN repo"
    },
    "setting": {
      "title": "Settings",
      "proxy": "Proxy",
      "sdPath": "Stable diffusion path",
      "sdPort": "Stable diffusion api port",
      "default": "Default",
      "save": "Save",
      "cancel": "Cancel"
    },
    "addTrainParam": {
      "title": "Add Train Paramerters",
      "search": "Search",
      "add": "Add"
    },
    "trainArgPreview": {
      "title": "Preview",
      "trainArg": "Train Arguments",
      "command": "Command",
      "ok": "OK"
    },
    "consoleOut": {
      "installing": "Installing",
      "complete": "Complete",
      "installFailed": "Install failed",
      "interrupt": "Interrupt"
    },
    "previewManager": {
      "title": "Preview Manager",
      "cancel": "Close",
      "apply": "Apply",
      "select": "Select",
      "sdwPath": "Stable diffusion web path",
      "download": "Download",
      "installPlugin": "Install Plugin",
      "titleConfig": "Config",
      "fieldPort": "port",
      "fieldSdModelPath": "models path",
      "useCnSource": "Use CN source",
      "actionDone": "Done",
      "downloadPreviewSuccess": "Download preview success",
      "downloadPreviewFailed": "Download preview failed:{{e}}",
      "downloadPluginSuccess": "Download plugin success",
      "downloadPluginFailed": "Download plugin failed:{{e}}"
    },
    "caption": {
      "title": "caption",
      "caption": "match",
      "cancel": "cancel",
      "save": "save",
      "captioning": "captioning",
      "threshold": "threshold"
    },
    "newProject": {
      "title": "New Project",
      "cancel": "Cancel",
      "create": "Create",
      "selectPath": "Select path",
      "selectProjectPath": "Select project path",
      "width": "width",
      "height": "height",
      "projectProps": "props",
      "name": "name",
      "path": "path"
    },
    "cropImage": {
      "title": "Crop image",
      "cancel": "Cancel",
      "rotate": "Rotate",
      "save": "Save",
      "flip": "Flip"
    },
    "importOriginal": {
      "title": "Import Original Images",
      "cancel": "Cancel",
      "import": "Import",
      "selectImage": "Select image",
      "importing": "Importing",
      "imported": "Imported",
      "importFailed": "Import failed",
      "importingProgress": "Importing {{index}}/{{total}}",
      "path": "Path",
      "deleteSelected": "Delete selected"
    }
  },
  "bottomBar": {
    "previewService": {
      "running": "running",
      "stopped": "stopped",
      "starting": "starting",
      "statusMessage": "Preview service {{status}}",
      "startBtn": "Start",
      "interruptBtn": "Interrupt",
      "stopBtn": "Stop"
    }
  },
  "panels": {
    "dataset": {
      "datasetFolders": "Dataset folders",
      "unused": "Unused",
      "all": "All",
      "tagFilter": "Tag filter",
      "edit": "Edit",
      "selectAll": "Select all",
      "copy": "Copy",
      "cut": "Cut",
      "delete": "Delete",
      "paste": "Paste",
      "captionSelectedImage": "Caption selected image",
      "autoCaption": "Auto caption",
      "deleteSelectedPreprocessImage": "Delete selected preprocess image",
      "removeSelectImageCaption": "Remove select image caption"
    },
    "trainConfig": {
      "newConfig": "New config",
      "name": "Name",
      "presetName": "Preset name",
      "modelName": "Model name",
      "pretrainModelNameOrPath": "Pretrain model name or path",
      "selectPretrainModel": "Select pretrain model",
      "fromLocal": "From local",
      "extraParams": "Extra params",
      "previewArgs": "Preview args",
      "addExtraParams": "Add extra params",
      "save": "Save",
      "launch": "Launch",
      "trainConfig": "Train config"
    },
    "monitor": {
      "status": "Status"
    },
    "models": {
      "selectExportPath": "Select export path",
      "generatePreviewImage": "Generate preview image",
      "export": "Export",
      "delete": "Delete",
      "prompt": "Prompt",
      "negativePrompt": "Negative Prompt",
      "width": "Width",
      "height": "Height",
      "steps": "Steps",
      "samplerName": "Sampler Name",
      "cfgScale": "cfg_scale",
      "seed": "Seed"
    },
    "original": {
      "preprocessImages": "Preprocess images",
      "cropImage": "Crop image",
      "excludeHasPreprocessImage": "Exclude has preprocess image",
      "preprocess": "Preprocess",
      "any": "Any",
      "nothing": "Nothing",
      "atLeastOne": "At least one",
      "moreThanOne": "More than one"
    }
  },
  "notice": {
    "saveProjectSuccess": "Project saved"
  },
  "start": {
    "title": "Lora trainer"
  },
  "args": {
    "no_metadata": "do not save metadata in output model",
    "unet_lr": "learning rate for U-Net",
    "text_encoder_lr": "learning rate for Text Encoder",
    "network_weights": "pretrained weights for network",
    "network_dim": "network dimensions (depends on each network)",
    "network_alpha": "alpha for LoRA weight scaling, default 1 (same as network_dim for same behavior as old version)",
    "network_dropout": "Drops neurons out of training every step (0 or None is default behavior (no dropout), 1 would drop all neurons)",
    "base_weights": "network weights to merge into the model before training",
    "no_half_vae": "do not use fp16/bf16 VAE in mixed precision (use float VAE)",
    "v2": "load Stable Diffusion v2.0 model",
    "v_parameterization": "enable v-parameterization training",
    "pretrained_model_name_or_path": "pretrained model to train, directory to Diffusers model or StableDiffusion checkpoint",
    "tokenizer_cache_dir": "directory for caching Tokenizer (for offline training)",
    "optimizer_type": "Optimizer to use",
    "use_8bit_adam": "use 8bit AdamW optimizer (requires bitsandbytes)",
    "use_lion_optimizer": "use Lion optimizer (requires lion-pytorch)",
    "learning_rate": "learning rate",
    "max_grad_norm": "Max gradient norm, 0 for no clipping",
    "optimizer_args": "additional arguments for optimizer",
    "lr_scheduler_type": "custom scheduler module",
    "lr_scheduler_args": "additional arguments for scheduler",
    "lr_scheduler": "scheduler to use for learning rate",
    "lr_warmup_steps": "Number of steps for the warmup in the lr scheduler (default is 0)",
    "lr_scheduler_num_cycles": "Number of restarts for cosine scheduler with restarts",
    "lr_scheduler_power": "Polynomial power for polynomial scheduler",
    "output_dir": "directory to output trained model",
    "output_name": "base name of trained model file",
    "huggingface_repo_id": "huggingface repo name to upload",
    "huggingface_repo_type": "huggingface repo type to upload",
    "huggingface_path_in_repo": "huggingface model path to upload files",
    "huggingface_token": "huggingface token",
    "huggingface_repo_visibility": "huggingface repository visibility ('public' for public, 'private' or None for private)",
    "save_state_to_huggingface": "save state to huggingface",
    "resume_from_huggingface": "resume from huggingface (ex: resume {repo_id}/{path_in_repo}:{revision}:{repo_type})",
    "async_upload": "upload to huggingface asynchronously",
    "save_precision": "precision in saving",
    "save_every_n_epochs": "save checkpoint every N epochs",
    "save_every_n_steps": "save checkpoint every N steps",
    "save_n_epoch_ratio": "save checkpoint N epoch ratio (for example 5 means save at least 5 files total)",
    "save_last_n_epochs": "save last N checkpoints when saving every N epochs (remove older checkpoints)",
    "save_last_n_epochs_state": "save last N checkpoints of state (overrides the value of --save_last_n_epochs)",
    "save_last_n_steps": "save checkpoints until N steps elapsed (remove older checkpoints if N steps elapsed)",
    "save_last_n_steps_state": "save states until N steps elapsed (remove older states if N steps elapsed, overrides --save_last_n_steps)",
    "save_state": "save training state additionally (including optimizer states etc.)",
    "resume": "saved state to resume training",
    "train_batch_size": "batch size for training",
    "max_token_length": "max token length of text encoder (default for 75, 150 or 225)",
    "mem_eff_attn": "use memory efficient attention for CrossAttention",
    "network_module": "network module to train",
    "logging_dir":"path to the directory for logging output",
    "log_with":"what logging tool(s) to use (choices: tensorboard, wandb, all)",
    "log_prefix":"add prefix for each log directory",
    "log_tracker_name":"name of tracker to use for logging",
    "log_tracker_config":"path to tracker config file to use for logging",
    "wandb_api_key":"specify WandB API key to log in before starting training (optional)",
    "noise_offset":"enable noise offset with this value (recommended: around 0.1)",
    "multires_noise_iterations":"enable multires noise with this number of iterations (recommended: around 6-10)",
    "multires_noise_discount": "set discount value for multires noise (has no effect without --multires_noise_iterations)",
    "adaptive_noise_scale": "add latent mean absolute value * this value to noise_offset (disabled if None, default)",
    "zero_terminal_snr": "fix noise scheduler betas to enforce zero terminal SNR",
    "min_timestep": "set minimum time step for U-Net training (0999, default is 0)",
    "max_timestep": "set maximum time step for U-Net training ... (11000, default is 1000)",
    "lowram": "enable low RAM optimization. e.g. load models to VRAM instead of RAM (for machines which have bigger VRAM than RAM such as Colab and Kaggle)",
    "sample_every_n_steps": "generate sample images ... every N steps",
    "sample_every_n_epochs": "generate sample images every N epochs (overwrites n_steps)",
    "sample_prompts": "file for prompts to generate sample images",
    "sample_sampler": "sampler (scheduler) type for sample images",
    "config_file": "using .toml instead of args to pass hyperparameter",
    "output_config": "output command line args to given .toml file",
    "metadata_title": "title for model metadata (default is output_name)",
    "metadata_author": "author name for model metadata",
    "metadata_description": "description for model metadata",
    "metadata_license": "license for model metadata",
    "metadata_tags": "tags for model metadata, separated by comma",
    "prior_loss_weight": "loss weight for regularization images",
    "train_data_dir": "directory for train images",
    "shuffle_caption": "shuffle comma-separated caption",
    "caption_extension": "extension of caption files",
    "caption_extention": "extension of caption files (backward compatibility)",
    "keep_tokens": "keep heading N tokens when shuffling caption tokens (token means comma separated strings)",
    "color_aug": "enable weak color augmentation",
    "flip_aug": "enable horizontal flip augmentation",
    "face_crop_aug_range": "enable face-centered crop augmentation and its range (e.g. 2.0,4.0)",
    "random_crop": "enable random crop (for style training in face-centered crop augmentation)",
    "debug_dataset": "show images for debugging (do not train)",
    "resolution": "resolution in training ('size' or 'width,height')",
    "cache_latents": "cache latents to main memory to reduce VRAM usage (augmentations must be disabled)",
    "vae_batch_size": "batch size for caching latents",
    "cache_latents_to_disk": "cache latents to disk to reduce VRAM usage (augmentations must be disabled)",
    "enable_bucket": "enable buckets for multi aspect ratio training",
    "min_bucket_reso": "minimum resolution for buckets",
    "max_bucket_reso": "maximum resolution for buckets",
    "bucket_reso_steps": "steps of resolution for buckets, divisible by 8 is recommended",
    "bucket_no_upscale": "make bucket for each image without upscaling",
    "token_warmup_min": "start learning at N tags (token means comma separated strings)",
    "token_warmup_step": "tag length reaches maximum on N steps (or Nmax_train_steps if N<1)",
    "dataset_class": "dataset class for arbitrary dataset (package.module.Class)",
    "save_model_as": "format to save the model (default is same to original)",
    "use_safetensors": "use safetensors format to save (if save_model_as is not specified)",
    "clip_skip": "use output of nth layer from back of text encoder (n>=1)",
    "full_fp16":"fp16 training including gradients",
    "max_train_epochs":"training epochs (overrides max_train_steps)",
    "max_data_loader_n_workers":"max num workers for DataLoader (lower is less main RAM usage, faster epoch start and slower data loading)",
    "persistent_data_loader_workers":"persistent DataLoader workers (useful for reduce time gap between epoch, but may use more memory)",
    "seed":"random seed for training",
    "gradient_checkpointing":"enable gradient checkpointing",
    "gradient_accumulation_steps":"Number of updates steps to accumulate before performing a backward/update pass",
    "mixed_precision":"use mixed precision",
    "xformers":"use xformers for CrossAttention",
    "vae":"path to checkpoint of vae to replace",
    "max_train_steps":"training steps",
    "reg_data_dir":"directory for regularization images"

  }
}
